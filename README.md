<h1 align="center"><b>Awesome-Large-Language-Model-in-Psychiatry</b></h1>
<p align="center">
    <a href="https://awesome.re"><img src="https://awesome.re/badge.svg" alt="awesome"></a>
    <!-- <a href="https://"><img src="https://img.shields.io/badge/-Website-grey?logo=svelte&logoColor=white" alt="Website"></a> -->
    <img src="https://img.shields.io/github/stars/RoarBoil/awesome-large-graph-model?color=yellow&label=Star" alt="Stars" >
    <img src="https://img.shields.io/github/forks/RoarBoil/awesome-large-graph-model?color=blue&label=Fork" alt="Forks" >
</p>

This repository contains a paper list related to **Large Language Models in Psychiatry**. For more details, please refer to our perspective paper : [Large Language Models in Psychiatry: Current Applications, Limitations, and Future Scope](https://www.biorxiv.org/content/10.1101/2023.11.04.565642v1)

our study has the following contributes:
1.	curating psychiatric-specific LLMs as well as medical LLMs with potential applications in psychiatry, along with training corpus;
2.	outlining potential directions for development of psychiatry LLMs from clinical, educational, and research perspectives;
3.	analyzing the limitations of existing LLMs in their application to current clinical psychiatry from eight different points;
4.	proposing a feasible experimental framework for determing whether an LLM meets the clinical standards for psychiatry;
5.	providing a simple evaluation prompt list and expert comments on the responses of three evaluated LLMs.

We will try our best to make this paper list updated. If you notice some related papers missing or have any suggestion, do not hesitate to contact us via pull requests at our repo.

# Papers

## **LLMs specifically developed for psychiatry and mental health care**
- [*Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies*] *Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data.*  [[paper]](https://dl.acm.org/doi/abs/10.1145/3643540) [2024.3]

- [*Arxiv*] *Mentalllama: Interpretable mental health analysis on social media with large language models.*   [[paper]](https://arxiv.org/abs/2309.13567) [2024.2]

- [*EMNLP 2023*] *SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations*.  [[paper]](https://aclanthology.org/2023.findings-emnlp.83/) [2023.12]

- [*Arxiv*] *Chatcounselor: A large language models for mental health support*.  [[paper]](https://arxiv.org/abs/2309.15461) [2023.9]

- [*Arxiv*] *Psy-llm: Scaling up global mental health psychological services with ai-based large language models*  [[paper]](https://arxiv.org/abs/2307.11991) [2023.7]

  **The date following the model represents the  most recent publication of the model**

## **Medical LLMs with psychiatry knowledge**
### 	***2024***

- [Arxiv] *Qilin-med: Multi-stage knowledge injection advanced medical large language model.* [[paper]](https://arxiv.org/abs/2310.09089) [2024.4]

- [AAAI] *Zhongjing: Enhancing the chinese medical capabilities of large language model through expert feedback and real-world multi-turn dialogue* [[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/29907) [2024.3]

- [Patterns] *Can large language models reason about medical questions?* [[paper]](https://www.cell.com/patterns/fulltext/S2666-3899(24)00042-4) [2024.3]

- [Journal of the American Medical Informatics Association] *Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks* [[paper]](https://academic.oup.com/jamia/advance-article-abstract/doi/10.1093/jamia/ocae037/7616487) [2024.2]

  

  ### ***2023***

- [Arxiv] *Bianque: Balancing the questioning and suggestion ability of health llms with multi-turn health conversations polished by chatgpt* [[paper]](https://arxiv.org/abs/2310.15896) [2023.12]

- [Github] *CareGPT: Medical LLM, Open Source Driven for a Healthy Future* [[paper]](https://github.com/WangRongsheng/CareGPT) [2023.12]

- [Arxiv] *MEDITRON-70B: Scaling Medical Pretraining for Large Language Models.* [[paper]](https://arxiv.org/abs/2311.16079) [2023.11]

- [Arxiv] *HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs.* [[paper]](https://arxiv.org/abs/2311.09774) [2023.11]

- [Arxiv] *Towards accurate differential diagnosis with large language models* [[paper]](https://arxiv.org/abs/2312.00164) [2023.11]

- [NPJ Digital Medicine] *A Study of Generative Large Language Model for Medical Research and Healthcare* [[paper]](https://www.nature.com/articles/s41746-023-00958-w) [2023.11]

- [Arxiv] *Alpacare: Instruction-tuned large language models for medical application.* [[paper]](https://arxiv.org/abs/2310.14558) [2023.10]

- [Arxiv] *MedAlpaca--An Open-Source Collection of Medical Conversational AI Models and Training Data* [[paper]](https://arxiv.org/abs/2304.08247) [2023.10]

- [Arxiv] *Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes.* [[paper]](https://arxiv.org/abs/2309.00237) [2023.9]

- [Arxiv] *Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding* [[paper]](https://arxiv.org/abs/2305.12031) [2023.8]

- [Arxiv] *Pmc-llama: Further finetuning llama on medical papers* [[paper]](https://arxiv.org/abs/2304.14454) [2023.8]

- [Arxiv] *Disc-medllm: Bridging general large language models and real-world medical consultation* [[paper]](https://arxiv.org/abs/2308.14346) [2023.8]

- [Github] *ShenNong-TCM: A Traditional Chinese Medicine Large Language Model.* [[paper]](https://github.com/michael-wzhu/ShenNong-TCM-LLM) [2023.8]

- [Github] *ChatMed: A Chinese Medical Large Language Model.* [[paper]](https://github.com/michael-wzhu/ChatMed) [2023.7]

- [Nature] *Large language models encode clinical knowledge* [[paper]](https://www.nature.com/articles/s41586-023-06291-2) [2023.7]

- [Arxiv] *ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation* [[paper]](https://arxiv.org/abs/2306.09968) [2023.6]

- [Arxiv] *HuatuoGPT, towards Taming Language Model to Be a Doctor* [[paper]](https://arxiv.org/abs/2306.09968) [2023.6]

- [Arxiv] *Huatuo: Tuning llama model with chinese medical knowledge* [[paper]](https://arxiv.org/abs/2304.06975) [2023.6]

- [Arxiv] *Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge* [[paper]](https://arxiv.org/abs/2303.14070) [2023.6]

- [Arxiv] *Doctorglm: Fine-tuning your chinese doctor is not a herculean task* [[paper]](https://arxiv.org/abs/2304.01097) [2023.6]

- [Github] *ChatGLM-Med: 基于中文医学知识的ChatGLM模型微调* [[paper]](https://github.com/SCIR-HI/Med-ChatGLM) [2023.5]

- [Arxiv] *Towards expert-level medical question answering with large language models* [[paper]](https://arxiv.org/abs/2305.09617) [2023.5]

- [Arxiv] *Capabilities of gpt-4 on medical challenge problems* [[paper]](https://arxiv.org/abs/2303.13375) [2023.4]

  

  ### ***2022***

- [Arxiv] *Galactica: A large language model for science* [[paper]](https://arxiv.org/abs/2211.09085) [2022.11]

  

  **The date following the model represents the  most recent publication of the model**

## Potential training corpus for psychiatric LLMs
- [Private] *UF Health IDR* [[link]](https://idr.ufhealth.org)
- [Limit] *n2c2* [[link]](https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/)
- [Limit] *PubMed* [[link]](https://pubmed.ncbi.nlm.nih.gov)
- [Public] *Wikipedia* [[link]](https://www.wikipedia.org/)
- [Public] *USMLE （MedQA）* [[link]](https://www.mdpi.com/2076-3417/11/14/6421)
- [Public] *MedMCQA* [[link]](https://proceedings.mlr.press/v174/pal22a.html)
- [Public] *PubMedQA * [[link]](https://arxiv.org/abs/1909.06146)
- [Limit] *HealthCareMagic100k* [[link]](https://arxiv.org/abs/2303.14070)
- [Public] *Anki Flashcards* [[link]](https://arxiv.org/abs/2304.08247k)
- [Public] *Wikidoc* [[link]](https://arxiv.org/abs/2304.08247)
- [Public] *CMeKG* [[link]](http://www5.zzu.edu.cn/nlp/info/1018/1785.htm)
- [Public] *Dreaddit* [[link]](https://arxiv.org/abs/1911.00133)
- [Public] *DepSeverity* [[link]](https://dl.acm.org/doi/abs/10.1145/3485447.3512128)
- [Public] *SDCNL* [[link]](https://link.springer.com/chapter/10.1007/978-3-030-86383-8_35)
- [Public] *CSSRS-Suicide* [[link]](https://www.frontiersin.org/articles/10.3389/fpubh.2023.1121290/full)
- [Limit] *PsyQA* [[link]](https://arxiv.org/abs/2106.01702)
- [Public] *S2ORC（selected）* [[link]](https://arxiv.org/abs/2304.14454)
- [Limit] *MedC-K* [[link]](https://arxiv.org/abs/2304.14454)
- [Limit] *MedC-I* [[link]](https://arxiv.org/abs/2304.14454)
- [Public] *MedDialog-CN* [[link]](https://arxiv.org/abs/2004.03329)
- [Public] *IMCS-V2* [[link]](https://academic.oup.com/bioinformatics/article-abstract/39/1/btac817/6947983)
- [Public] *CHIP-MDCFNPC* [[link]](https://arxiv.org/abs/2106.08087)
- [Public] *cMedQA2* [[link]](https://ieeexplore.ieee.org/abstract/document/8548603/)
- [Public] *webMedQA* [[link]](https://link.springer.com/article/10.1186/s12911-019-0761-8)
- [Public] *Huatuo-26m* [[link]](https://arxiv.org/abs/2305.01526)
- [Public] *xywy-KG* [[link]](https://arxiv.org/abs/2305.01526)
- [Public] *39Health-KG* [[link]](https://arxiv.org/abs/2305.01526)
- [Public] *cMedQA-KG* [[link]](https://ieeexplore.ieee.org/abstract/document/8548603/)
- [Public] *MD-EHR* [[link]](https://arxiv.org/abs/2306.09968)
- [Public] *SoulChatCorpus* [[link]](https://aclanthology.org/2023.findings-emnlp.83/)
- [Public] *ChatMed_Consult_Dataset* [[link]](https://github.com/michael-wzhu/ChatMed)
- [Public] *Clinical Guideline-dataset* [[link]](https://arxiv.org/abs/2311.16079)
- [Public] *CBLUE* [[link]](https://arxiv.org/abs/2106.08087)
- [Public] *MedInstruct-52K* [[link]](https://arxiv.org/abs/2304.08247)
- [Public] *CMtMedQA* [[link]](https://ojs.aaai.org/index.php/AAAI/article/view/29907)
- [Public] *SMILE* [[link]](https://arxiv.org/abs/2305.00450)
- [Public] *Psych8k* [[link]](https://arxiv.org/abs/2308.14346)
- [Public] *Depression_Reddit* [[link]](https://aclanthology.org/W18-5903/)
- [Public] *CLPsych15* [[link]](https://aclanthology.org/W15-1204.pdf)
- [Public] *T-SID* [[link]](https://link.springer.com/article/10.1007/s00521-021-06208-y)
- [Public] *SWMH* [[link]](https://link.springer.com/article/10.1007/s00521-021-06208-y)
- [Public] *SAD* [[link]](https://dl.acm.org/doi/abs/10.1145/3411763.3451799)
- [Public] *CAMS* [[link]](https://arxiv.org/abs/2207.04674)
- [Public] *IRF* [[link]](https://arxiv.org/abs/2305.18727)
- [Public] *MultiWD* [[link]](https://www.techrxiv.org/doi/full/10.36227/techrxiv.22816586.v1)
- [Public] *Asclepius-data* [[link]](https://arxiv.org/abs/2309.00237)
- [Public] *DISC-Med-SFT* [[link]](https://arxiv.org/abs/2308.14346)

## Cite
Please consider citing our [perspective paper](Link_to_paper) if you find this repository helpful:
```
@article{citation_here
}
```